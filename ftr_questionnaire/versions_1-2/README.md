# Readme

This readme is designed to help interested researchers re-construct the methods presented in Robertson & Roberts (2020), and in Robertson, Roberts, Dunbar, & Majid (2020).

These versions of the FTR questionnaire were used to gather data in four experiments, which we refer to here consecutively as numbers 1-4. These correspond to the experiment numbers given in Robertson & Roberts (2020). Because Robertson, Roberts, Dunbar, & Majid (2020) uses a matched sample of items across all experiments, item subsetting is not given per experiment.

# data subsetting by publication

## Robertson, Roberts, Dunbar, & Majid (2020).
### study Ia
The items which were presented to participant in the FTR elicitation task can be generated by subsetting `questions.xlsx` such that `e2_&_e4 == "in"`. 

Two items were cut because inclusion of modal or tense words in the prompt make answers impossible for the FTR classifier to identify. These can be created by  further subsetting such that `miscode_cut == "ok"`. And 1 items was cut because participants appeared to misunderstand the question as refering to present time. This can be generated by setting `understand == "understood"`. 

In analyses which use `frame_distance` questions where `frame_distance` is in `["ongoing_prediction","indeterminate"]` are further excluded.

### study Ib
The 29 items which were presented to participants in the FTR elicitation task can be generated by subsetting `questions.xlsx` such that `e2_&_e4 == "in"`. 

Two items were cut because inclusion of modal or tense words in the prompt make answers impossible for the FTR classifier to identify. These can be created by  further subsetting such that `miscode_cut == "ok"`. And 1 items was cut because participants appeared to misunderstand the question as refering to present time. This can be generated by setting `understand == "understood"`. 

Additionally, 2 questions were cut because inclusion of a (then past time) ultimate time reference ("by 2018") meant they referred to past time. These can be generated by further subsetting such that `question_no` is not in `[37,39,39]`. 

<!-- In analyses which use `frame_distance` questions where `frame_distance` is in `["ongoing_prediction","indeterminate"]` are further excluded. -->

### study II
All items in `questions_e3.xlsx` were presented to participants in experiment three. 

The items which were cut because inclusion of modal or tense words in the prompt make answers impossible for the FTR classifier to identify can be generated by  further subsetting such that `miscode_cut == "ok"`, and items which were cut because participants appeared to misunderstand the question as refering to present time can be generated by setting `understand == "understood"`. In this case, the item which was cut because inclusion of a (then past time) ultimate time reference ("by 2018") meant they referred to past time is indexed by `miscode_cut`.


### experiment two
The items which are used in the analyses in Robertson, Robertson, Dunbar, & Majid (2020) can be generated by subsetting `questions_e3.xlsx` such that: `used_to_calc_means == 'in'`.


## Robertson & Roberts (2020)

### experiment one
The items which are used can be generated by subsetting `questions.xlsx` such that: `miscode_cut == "ok"`,  `understand == "understood"`, and `e1_uploaded == "in"`. The matched sample generated by additionally subsetting such that  `e1_intersection == "in"`.

### experiment two 
The items which are used can be generated by subsetting `questions.xlsx` such that: `e2_&_e4 == "in"`, `miscode_cut == "ok"`, and `understand == "understood"`.

### experiment three
 The items which are used can be generated by subsetting `questions_e3.xlsx` such that: `miscode_cut == "ok"`, and `understand == "understood"`.
 
 ### experiment four
Identically to experiment two, the items which were used can be generated by subsetting `questions.xlsx` such that: `e2_&_e4 == "in"`, `miscode_cut == "ok"`, and `understand == "understood"`.


## further notes
Readers will note that the questions which comprise the test battery in experiment three are different from those in exps. 1, 2, and 4. However, some questions are the same. These are indexed by the `uneek` collumn, i.e. questions with the same value of `uneek` are identical between `questions.xlsx` and `questions_e3.xlsx`.

